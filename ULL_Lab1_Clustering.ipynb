{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Language Learning, Lab1\n",
    "\n",
    "## Adriaan de Vries (10795227), Verna Dankers (10761225)\n",
    "\n",
    "Before being able to run this code, please import the following libraries and set the following paths to the datasets. Afterwards, the code should run without issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Requirements\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from tabulate import tabulate\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.cluster.vq import whiten, kmeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from os.path import isfile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to datasets\n",
    "bow2_filename = \"data/bow2.words\"\n",
    "bow5_filename = \"data/bow5.words\"\n",
    "deps_filename = \"data/deps.words\"\n",
    "simlex_filename = \"data/SimLex-999.txt\"\n",
    "men_filename = \"data/men/MEN_dataset_natural_form_full\"\n",
    "analogy_filename = \"data/questions-words.txt\"\n",
    "common_words_filename = \"data/common_words.words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not isfile(bow2_filename.split(\".\")[0] + \".txt\"): \n",
    "    glove2word2vec(bow2_filename, bow2_filename.split(\".\")[0] + \".txt\")\n",
    "if not isfile(bow5_filename.split(\".\")[0] + \".txt\"): \n",
    "    glove2word2vec(bow5_filename, bow5_filename.split(\".\")[0] + \".txt\")\n",
    "if not isfile(deps_filename.split(\".\")[0] + \".txt\"): \n",
    "    glove2word2vec(deps_filename, deps_filename.split(\".\")[0] + \".txt\")\n",
    "bow2 = KeyedVectors.load_word2vec_format(bow2_filename.split(\".\")[0] + \".txt\", binary=False)\n",
    "bow2.init_sims(replace=True)\n",
    "print(\"bow2 done.\")\n",
    "bow5 = KeyedVectors.load_word2vec_format(bow5_filename.split(\".\")[0] + \".txt\", binary=False)\n",
    "bow5.init_sims(replace=True)\n",
    "print(\"bow5 done.\")\n",
    "deps = KeyedVectors.load_word2vec_format(deps_filename.split(\".\")[0] + \".txt\", binary=False)\n",
    "deps.init_sims(replace=True)\n",
    "print(\"deps done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "common_words = []\n",
    "with open(common_words_filename, 'r') as f:\n",
    "    for line in f:\n",
    "        # 'fig.' is a word, changing it to 'fig' here.\n",
    "        if line[-2] == '.':\n",
    "            line = line[:-2]\n",
    "        common_words.append(line.split()[0])\n",
    "for key in tqdm(common_words):\n",
    "    data.append(bow5[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "whitened_data = whiten(data)\n",
    "x=[]\n",
    "aic=[]\n",
    "bic=[]\n",
    "for k in tqdm(range(2, 40)):\n",
    "    gmm = GaussianMixture(n_components=k, n_init=4).fit(np.array(whitened_data))\n",
    "    labels = gmm.predict(whitened_data)\n",
    "    aic.append(gmm.aic(whitened_data))\n",
    "    bic.append(gmm.bic(whitened_data))\n",
    "    x.append(k)\n",
    "plt.plot(x, aic, label = 'AIC')\n",
    "plt.plot(x, bic, label = 'BIC')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_and_TSNE(embeddings, words, n_clusters=27):\n",
    "    word_embeddings = whiten([embeddings[key] for key in words])\n",
    "    gmm = GaussianMixture(n_components=n_clusters, n_init=10).fit(np.array(word_embeddings))\n",
    "    labels = gmm.predict(word_embeddings)\n",
    "    TSNE_fit = TSNE().fit_transform(word_embeddings)\n",
    "    return labels, TSNE_fit\n",
    "\n",
    "\n",
    "label_lists = []\n",
    "TSNE_fits = []\n",
    "for embedding in tqdm([bow2, bow5, deps]):\n",
    "    labels, TSNE_fit = cluster_and_TSNE(embedding, common_words)\n",
    "    label_lists.append(labels)\n",
    "    TSNE_fits.append(TSNE_fit)\n",
    "    \n",
    "finaldata = [sorted(list(zip(label_lists[embedding_method], TSNE_fits[embedding_method][:,0], TSNE_fits[embedding_method][:,1], common_words))) for embedding_method in range(3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "father_cluster_labels = []\n",
    "father_clusters = []\n",
    "for i, f in enumerate(finaldata):\n",
    "    for point in f:\n",
    "        if point[3] == 'father':\n",
    "            father_cluster_labels.append(point[0])\n",
    "    cluster = []\n",
    "    for point in f:\n",
    "        if point[0] == father_cluster_labels[i]:\n",
    "            cluster.append(point[3])\n",
    "    father_clusters.append(cluster)\n",
    "\n",
    "\n",
    "father_clusters = [set(f) for f in father_clusters]\n",
    "    \n",
    "intersection = father_clusters[0]\n",
    "for c in father_clusters[1:]:\n",
    "    intersection = intersection & c\n",
    "    \n",
    "remainders = [f-intersection for f in father_clusters]\n",
    "    \n",
    "pprint([sorted(x) for x in remainders])\n",
    "\n",
    "pprint(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_tsne_clusters(data, labels, max_groups_to_plot = 10**4):\n",
    "    \"\"\"\n",
    "    makes plots of data given in the form of a list of lists \n",
    "    of tuples consisting of (<cluster label>, <x>, <y>, <word>)\n",
    "    labels is a list of equal length to data, giving the titles\n",
    "    of the plots.\n",
    "    \n",
    "    plots both the unlabeled clusters, and the clusters so \n",
    "    that each data point is annotated with the appropriate\n",
    "    word. \n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    figure.set_size_inches(15, 10)\n",
    "    \n",
    "    for i, (d, l) in enumerate(zip(data, labels)):\n",
    "        groups = []\n",
    "        cluster = d[0][0]\n",
    "        group = []\n",
    "        for datapoint in d:\n",
    "            if datapoint[0] != cluster:\n",
    "                groups.append(group)\n",
    "                cluster = datapoint[0]\n",
    "                group = []\n",
    "            group.append(datapoint)\n",
    "        groups.append(group)\n",
    "        plt.subplot(2, len(data), i+1)\n",
    "        for group in groups[:max_groups_to_plot]:\n",
    "            group = np.array(group)\n",
    "            xy = group[:,1:3].astype(np.float64)\n",
    "            plt.scatter(xy[:,0], xy[:,1], alpha = 0.5)\n",
    "            plt.title(l)\n",
    "        plt.subplot(2, len(data), i+1+len(data))\n",
    "        for group in groups[:max_groups_to_plot]:\n",
    "            group = np.array(group)\n",
    "            xy = group[:,1:3].astype(np.float64)\n",
    "            plt.scatter(xy[:,0], xy[:,1], alpha = 0.5)\n",
    "            for point, xypoint in zip(group, xy):\n",
    "                plt.annotate(point[3], xy=(xypoint[0],xypoint[1]), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_tsne_clusters(finaldata, ['bow2', 'bow5', 'deps'], 5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ml1labs]",
   "language": "python",
   "name": "Python [ml1labs]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
